{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6_qQSRXbL4f"
   },
   "source": [
    "<center> <h1> FP2 - Creating the Dataset </h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBuHSgq5bOSc"
   },
   "source": [
    "<center> <h3> Glenn Billman, Shreya Yalamanchili, Sam Zlota </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9A4drLGbR3u"
   },
   "source": [
    "In the below code, we will first create a dataframe with 10,000 random songs using a random search function. Using the Spotify Song IDs of the songs, we will then access the API and get the features we are conducting our project on. We will then add all of these feeatures and the song information to a final dataframe and convert that to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXBGGDbBOwTf"
   },
   "outputs": [],
   "source": [
    "# adapted from https://stmorse.github.io/journal/spotify-api.html and \n",
    "# https://github.com/ZipBomb/spotify-song-suggestion/blob/master/random_song.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYfvKT5zOwTm"
   },
   "outputs": [],
   "source": [
    "# imports the required libaries\n",
    "import base64\n",
    "import json\n",
    "import random\n",
    "import urllib\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Spotify API client id and secret id\n",
    "CLIENT_ID = '6480491e23264b429963178e13b36b1e'\n",
    "CLIENT_SECRET = 'cbd284788bf846b6bf7fd2b870fa1da5'\n",
    "\n",
    "# Spotify API URIs\n",
    "SPOTIFY_TOKEN_URL = \"https://accounts.spotify.com/api/token\"\n",
    "SPOTIFY_API_BASE_URL = \"https://api.spotify.com\"\n",
    "API_VERSION = \"v1\"\n",
    "SPOTIFY_API_URL = \"{}/{}\".format(SPOTIFY_API_BASE_URL, API_VERSION)\n",
    "words_txt = pd.read_csv('word_list.txt',header=None)\n",
    "word_list = words_txt[0].to_list()\n",
    "\n",
    "# gets a token to access the API with our client id and secret id\n",
    "def get_token():\n",
    "    client_token = base64.b64encode(\"{}:{}\".format(CLIENT_ID, CLIENT_SECRET).encode('UTF-8')).decode('ascii')\n",
    "    headers = {\"Authorization\": \"Basic {}\".format(client_token)}\n",
    "    payload = {\"grant_type\": \"client_credentials\"}\n",
    "    token_request = requests.post(SPOTIFY_TOKEN_URL, data=payload, headers=headers)\n",
    "    access_token = json.loads(token_request.text)[\"access_token\"]\n",
    "    return access_token\n",
    "\n",
    "# requests a random valid song from Spotify\n",
    "def request_valid_song(access_token, iterations):\n",
    "    # creates a dataframe with the song information and search term\n",
    "    song_df = pd.DataFrame(columns=['track','artist','id','search term'])\n",
    "    songs = 0 # sets the count to 0 \n",
    "    pbar = tqdm(total=iterations,position=0, leave=True) # sets a progress bar\n",
    "\n",
    "    while songs < iterations:\n",
    "    \n",
    "        # search term for random search\n",
    "        search_term = random.choice(word_list)\n",
    "\n",
    "        # make a request for the Search API with pattern and random index\n",
    "        authorization_header = {\"Authorization\": \"Bearer {}\".format(access_token)}\n",
    "\n",
    "        # cap the max number of requests\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                song_request = requests.get(\n",
    "                    '{}/search?q={}&type=track&offset={}'.format(\n",
    "                        SPOTIFY_API_URL,\n",
    "                        search_term,\n",
    "                        random.randint(0, 200)\n",
    "                    ),\n",
    "                    headers = authorization_header\n",
    "                )\n",
    "                song_info = random.choice(json.loads(song_request.text)['tracks']['items'])\n",
    "                artist = song_info['artists'][0]['name']\n",
    "                song = song_info['name']\n",
    "                song_id = song_info['id']\n",
    "                break\n",
    "            except: # not all words will bring up a song, so just continue on \n",
    "                continue\n",
    "                \n",
    "        # sets the song we just searched\n",
    "        song_to_append = pd.DataFrame([[song,artist,song_id,search_term]],columns=['track','artist','id',\n",
    "                                                                                   'search term'])\n",
    "        \n",
    "        # appends the new song to the dataframe\n",
    "        song_df = song_df.append(song_to_append,ignore_index = True)\n",
    "\n",
    "        # increases the count and the progress bar\n",
    "        songs+=1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msCZYr4hOwTs"
   },
   "outputs": [],
   "source": [
    "songs_1000 = request_valid_song(get_token(),1000) # get 1000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmR2iA6oOwTv"
   },
   "outputs": [],
   "source": [
    "songs_10000 = request_valid_song(get_token(),10000) # get 10000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hz-pMq17OwTx"
   },
   "outputs": [],
   "source": [
    "# convert both dataframes to csv files\n",
    "songs_10000.to_csv('10000_songs.csv')\n",
    "songs_1000.to_csv('1000_songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VT7bPHnaOwT1"
   },
   "outputs": [],
   "source": [
    "# gets the song traids (attributes) of the song ids given a dataframe with the ids\n",
    "def get_traits(df):\n",
    "    AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    # POST\n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': CLIENT_ID,\n",
    "        'client_secret': CLIENT_SECRET,\n",
    "    })\n",
    "\n",
    "    # convert the response to JSON\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token = auth_response_data['access_token']\n",
    "    \n",
    "    headers = {\n",
    "    'Authorization': 'Bearer {token}'.format(token=access_token)\n",
    "    }\n",
    "    \n",
    "    # base URL of all Spotify API endpoints\n",
    "    BASE_URL = 'https://api.spotify.com/v1/'\n",
    "\n",
    "    # creates a dataframe with all of our features\n",
    "    attr_df = pd.DataFrame(columns=['artist','track','id','danceability','energy','key','loudness','mode',\n",
    "                                           'speechiness','acousticness','instrumentalness','liveness',\n",
    "                                           'valence','tempo','duration_ms'])\n",
    "    pbar = tqdm(total=len(df['id']),position=0, leave=True)\n",
    "    \n",
    "    # for each song, get the attributes\n",
    "    for i in range(len(df['id'])): \n",
    "        try:\n",
    "            track_id = df['id'][i]\n",
    "            r = requests.get(BASE_URL + 'audio-features/' + track_id, headers=headers)\n",
    "            r = r.json()\n",
    "            \n",
    "            # store the new attributes in a dataframe\n",
    "            attr_to_append = pd.DataFrame([[df['artist'][i],df['track'][i],df['id'][i], r['danceability'],r['energy'], \n",
    "                                          r['key'],r['loudness'],r['mode'], r['speechiness'],r['acousticness'],\n",
    "                                          r['instrumentalness'],r['liveness'],r['valence'],r['tempo'],r['duration_ms']]],\n",
    "                                          columns=['artist','track','id','danceability','energy','key','loudness','mode',\n",
    "                                                   'speechiness','acousticness','instrumentalness','liveness',\n",
    "                                                    'valence','tempo','duration_ms'])\n",
    "            # append the new attributes to the dataframe\n",
    "            attr_df = attr_df.append(attr_to_append,ignore_index = True)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        except: # sometimes attributes will not be found\n",
    "            # print the song id, update the progress bar, and continue on \n",
    "            print(df['id'][i])\n",
    "            pbar.update(1)\n",
    "            continue \n",
    "        \n",
    "    pbar.close()\n",
    "    return attr_df\n",
    "\n",
    "\n",
    "# gets the popularity index of the song ids given a dataframe with the ids\n",
    "def get_popularity(df):\n",
    "    AUTH_URL = 'https://accounts.spotify.com/api/token'\n",
    "\n",
    "    # POST\n",
    "    auth_response = requests.post(AUTH_URL, {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'client_id': CLIENT_ID,\n",
    "        'client_secret': CLIENT_SECRET,\n",
    "    })\n",
    "\n",
    "    # convert the response to JSON\n",
    "    auth_response_data = auth_response.json()\n",
    "\n",
    "    # save the access token\n",
    "    access_token = auth_response_data['access_token']\n",
    "    \n",
    "    headers = {\n",
    "    'Authorization': 'Bearer {token}'.format(token=access_token)\n",
    "    }\n",
    "    \n",
    "    # base URL of all Spotify API endpoints\n",
    "    BASE_URL = 'https://api.spotify.com/v1/'\n",
    "\n",
    "    # create a dataframe to store the indexes\n",
    "    attr_df = pd.DataFrame(columns=['id','popularity'])\n",
    "    pbar = tqdm(total=len(df['id']),position=0, leave=True)\n",
    "    \n",
    "    # for every song, get the popularity index\n",
    "    for i in range(len(df['id'])): \n",
    "        try:\n",
    "            track_id = df['id'][i]\n",
    "            r = requests.get(BASE_URL + 'tracks/' + track_id, headers=headers)\n",
    "            r = r.json()\n",
    "\n",
    "            # store the index we found in a few dataframe\n",
    "            attr_to_append = pd.DataFrame([[df['id'][i], r['popularity']]],\n",
    "                                          columns=['id','popularity'])\n",
    "            # append the index we found to the dataframe\n",
    "            attr_df = attr_df.append(attr_to_append,ignore_index = True)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        except: # sometimes the index will not be found\n",
    "            # print the song id, update the progress bar, and continue on \n",
    "            print(df['id'][i])\n",
    "            pbar.update(1)\n",
    "            continue \n",
    "        \n",
    "    pbar.close()\n",
    "    return attr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BguubDOOwT_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traits_10000 = get_traits(songs_10000) # gets the attributes of 100000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YDBjBskOwUG"
   },
   "outputs": [],
   "source": [
    "traits_10000.to_csv('traits_10000.csv') # converts the dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_10000 = get_popularity(songs_10000) # gets the popularity index of each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3MV8Mg7bi7e"
   },
   "outputs": [],
   "source": [
    "both_songs_10000 = pd.merge(traits_10000, pop_10000, how='left', on='id') # merges the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_songs_10000.to_csv('song_info_10000.csv') # converts the final dataframe to a csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FP2_Dataset_Parsed.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
